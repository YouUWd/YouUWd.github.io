{"meta":{"title":"YouN","subtitle":null,"description":null,"author":"Timmy","url":"http://youuwd.github.io","root":"/"},"pages":[{"title":"tags","date":"2019-09-11T08:39:26.000Z","updated":"2021-08-12T11:26:15.450Z","comments":false,"path":"tags/index.html","permalink":"http://youuwd.github.io/tags/index.html","excerpt":"","text":""},{"title":"一粒微尘","date":"2019-09-12T05:40:35.000Z","updated":"2021-08-12T02:30:08.651Z","comments":true,"path":"about/index.html","permalink":"http://youuwd.github.io/about/index.html","excerpt":"","text":"工作经历2017.8 -阿里云分布式数据库 技术专家项目名称：分布式数据库项目职责：管理及售卖平台开发维护，数据链路CDC开发 分布式数据库管控平台的完整重构。 监控体系搭建开发。 基于监控系统的报警平台开发及自动运维平台的开发。 阿里云分布式数据库API的可用性优化升级。 主导分布式数据库一体化售卖体系的设计及开发。 基于分布式数据库的分散的binlog构建一份完整有序，具有事务保障的逻辑binlog。 基于分布式数据库的逻辑binlog，构建CDC生态，将分布式数据库TP的数据，同步到各个目标，包括且不限于AP型数据库，Kafka消息队列，大数据Maxcompute等。 2014-09 — 2017-06China Reading Ltd(腾讯文学) 资深级工程师项目名称：移动后端研发组项目职责：书城运营活动项目优化，重构，基础服务重构 通用抽奖模板服务，负责各平台活动抽奖模块抽奖逻辑及奖品数据存储，抽象抽奖相关逻辑（概率，各种上限，发放规则等）提供给抽奖相关活动使用。 通用状态服务，存储用户相关状态标识；为各业务端提供通用状态读写服务，减少各业务模块之间的耦合度。 用户VIP体系服务，原积分体系转换为消费体系；为各个终端提供日调用量超过10亿级等级查询服务以及1亿级消费写服务，以及5000w+用户数据落库。 用户及书籍粉丝体系，用户对一本书产生消费行为，对应产生的书籍粉丝数和用户粉丝值，已经对应的排行数据。 用户排行榜服务，积分榜；根据积分的变更，维护TOP N名用户的榜单。 书城推广活动支持。 高峰流量期间，服务升级，扩容及非关键路径服务的降级。 2011-07 — 2014-08京东商城 中级软件工程师项目名称：交易平台项目职责：参与购物车和下单系统重构，主要负责下单相关新需求的开发，订单中间件系统升级 设计并开发了京东单品页的购买配送服务，单机双实例压力测试处理能力达到8000+TPS，系统自2012年12月份以来主服务每日提供2亿+次不间断的服务(线上运行近2年无宕机)，是京东上亿级别调用的服务之一，解决了以往大促销时商品页配送及购买加载缓慢甚至无法加入购物车的现象，提前告知用户商品能否在所在区域下单，节省用户大量的时间，也为后续系统抵挡了大部分的压力。 京东厂商直送商品下单服务，311及411配送，大家电晚间配送，京豆支付等项目的开发设计。 用户收货地址，支付配送方式信息相关数据迁移。 订单中间件去Oracle，设计MySQL分库分表方案。现有订单中间件是由一台Oracle数据库服务器存储订单热数据，当并发量大的时候，数据库服务器成为瓶颈，采用分库分表方案解决了单台Oracle数据库服务器负载过高及连接数不足的短板。为确保重构的正确性，上线之前使用TcpCopy双写数据进行对比，确保业务100%无漏洞。 订单快照信息1T+Redis数据读写服务，历史订单数据存储。 促销活动各种优化及降级方案的设计，及其他订单相关需求开发。"},{"title":"categories","date":"2019-09-12T05:35:18.000Z","updated":"2021-08-12T02:30:08.651Z","comments":false,"path":"categories/index.html","permalink":"http://youuwd.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"通用开发环境搭建","slug":"dev-prepare","date":"2021-08-12T07:32:34.000Z","updated":"2021-08-12T12:42:54.377Z","comments":true,"path":"2021/08/12/dev-prepare/","link":"","permalink":"http://youuwd.github.io/2021/08/12/dev-prepare/","excerpt":"","text":"以下文件安装默认目录为~/dev ~/dev 后续路径为解压包后的完整路径 Java 开发环境搭建Java SE Downloads 一般选择压缩包(Compressed Archive)安装, 这样可以定制化安装到指定目录。 如果是ARM架构，建议使用Zulu -CA-macos-aarch64 ARM 64-bit 环境变量123JAVA_HOME=~/dev/zulu8.56.0.23-ca-jdk8.0.302-macosx_aarch64/zulu-8.jdk/Contents/HomePATH=$PATH:$JAVA_HOME/binCLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar MAVEN 安装及配置 下载tar.gz 解压即可，最好不要修改settings.xml里面的localRepository，因为idea内置maven，默认的目录为.m2，因此如果要修改settings.xml，需要一并修改。 环境变量12MAVEN_HOME=~/dev/apache-maven-3.8.1PATH=$PATH:$MAVEN_HOME/bin MySQL Client 安装 MySQL Server 在mac机器上一般使用docker(也有arm版了)安装，以便切换不同的mysql版本。 MySQL Client 则可以使用mysql的安装包里面工具。如果是ARM架构，可选择macos11-arm64 arm64.tar.gz 环境变量1PATH=$PATH:~/dev/mysql-8.0.26-macos11-arm64/bin Github GitLab SSH keys 配置 ed25519加密解密很快,生成时间短而且安全性更高,rsa则加密解密稍慢,生成时间长,安全性没有ed25519高,只是rsa基本都是默认,所以用的人更多,但是建议转换为ed25519,网站软件现在基本都支持了. Github (ed25519)1ssh-keygen -t ed25519 -C &quot;your_email@example.com&quot; GitLab (rsa)1ssh-keygen -t rsa -C &quot;your_email@example.com&quot; 配置ssh config123456789101112131415#将上面生成的id_rsa 及 id_rsa.pub 分别移动到github和gitlab目录# cat ~/.ssh/config#gitlabHost gitlab HostName gitlab.*.com PreferredAuthentications publickey IdentityFile ~/.ssh/gitlab/id_rsa#githubHost github AddKeysToAgent yes UseKeychain yes HostName github.com PreferredAuthentications publickey IdentityFile ~/.ssh/github/id_ed25519","categories":[],"tags":[{"name":"java maven docker mysql gitlab github","slug":"java-maven-docker-mysql-gitlab-github","permalink":"http://youuwd.github.io/tags/java-maven-docker-mysql-gitlab-github/"}]},{"title":"安装zsh及主题(Mac)","slug":"zsh","date":"2021-08-11T05:55:06.000Z","updated":"2021-08-12T02:30:08.650Z","comments":true,"path":"2021/08/11/zsh/","link":"","permalink":"http://youuwd.github.io/2021/08/11/zsh/","excerpt":"","text":"Install Homebrew1/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot; Install Oh My Zsh1sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot; Install Powerline fonts12345678# clonegit clone https://github.com/powerline/fonts.git --depth=1# installcd fonts./install.sh# clean-up a bitcd ..rm -rf fonts 配置 zsh 支持图标","categories":[],"tags":[{"name":"zsh oh-my-zsh","slug":"zsh-oh-my-zsh","permalink":"http://youuwd.github.io/tags/zsh-oh-my-zsh/"}]},{"title":"MySQL-architecture","slug":"mysql-architecture","date":"2021-06-30T02:25:18.000Z","updated":"2021-08-12T02:30:08.650Z","comments":true,"path":"2021/06/30/mysql-architecture/","link":"","permalink":"http://youuwd.github.io/2021/06/30/mysql-architecture/","excerpt":"","text":"MySQL is Relational Database Management system which is free Open Source Software Under GNU License. It is also supported by Oracle Company .It is fast , scalable, easy to use database management System. MySQL support many operation system like Windows, Linux, MacOS etc. MySQL is Structured Query Language which is used to manipulate, manage and retrieve data with the help of various Queries. MySQL is developed and supported by MySQL AB which is a Swedish Company and written in C and C++ programming language. It was developed by Michael Widenius and David Hughes .It is often used to say that MySQL is named after the name of daughter of the co-founder MIchael Widenius whose name is ‘My’. Architecture of MySQL: Architecture of MySQL describes the relation among the different components of MySQL System. MySQL follow Client-Server Architecture. It is designed so that end user that is Clients can access the resources from Computer that is server using various networking services. The Architecture of MySQL contain following major layer’s : Client Server Storage Layer Client Layer:This layer is the topmost layer in the above diagram. The Client give request instructions to the Serve with the help of Client Layer .The Client make request through Command Prompt or through GUI screen by using valid MySQL commands and expressions .If the Expressions and commands are valid then the output is obtained on the screen. Some important services of client layer are : Connection Handling. Authentication. Security. Connection Handling :When a client send request to the server and server will accept the request and the client is connected .. When Client is connected to the server at that time , a client get it’s own thread for it’s connection. With the help of this thread all the queries from client side is executed. Authentication :Authentication is performed on the server side when client is connected to the MySQL server. Authentication is done with the help of username and password. Security :After authentication when the client gets connected successfully to MySQL server, the server will check that a particular client has the privileges to issue in certain queries against MySQL server. Server Layer:The second layer of MySQL architecture is responsible for all logical functionalities of relational database management system of MySQL. This Layer of MySQL System is also known as “Brain of MySQL Architecture”. When the Client give request instructions to the Server and the server gives the output as soon as the the instruction is matched. The various sub components of MySQL server are: Thread Handling –When a client send request to the server and server will accept the request and the client is connected .. When Client is connected to the server at that time , a client get it’s own thread for it’s connection. This thread is provided by thread handling of Server Layer. Also the queries of client side which is executed by the thread is also handled by Thread Handling module. Parser –A Parser is a type of Software Component that built a data structure(parse tree) of given input . Before parsing lexical analysis is done i.e. input is broken into number of tokens . After the data is available in the smaller elements parser perform Syntax Analysis , Semantics Analysis after that parse tree is generated as output. Optimizer –As soon as the parsing is done , various types of optimization techniques are applied at Optimizer Block. These techniques may include rewriting the query, order of scanning of tables and choosing the right indexes to use etc. Query Cache –Query Cache stores the complete result set for inputted query statement. Eve before Parsing , MySQL Server consult query cache . When client write a query , if the query written by client is identical in the cache then the server simply skip the parsing, optimization and even execution, it just simply display the output from the cache. Buffer and Cache –Cache and will buffer store the previous query or problem asked by user. When User write a query then it firstly goes to Query Cache then query cache will check that the same query or problem is available in the cache. If the same query is available then it will provide output without interfering Parser, Optimizer. Table Metadata Cache –The metadata cache is a reserved area of memory used for tracking information on databases, indexes, or objects. The greater the number of open databases, indexes, or objects, the larger the metadata cache size. Key Cache –A key cache is an index entry that uniquely identifies an object in a cache. By default, edge servers cache content based on the entire resource path and a query string. Storage Layer:This Storage Engine Layer of MySQL Architecture make it’s unique and most preferable for developer’s . Due to this Layer MySQL layer is counted as the mostly used RDBMS and is widely used. In MySQL server , for different situations and requirement’s different types of storage engines are used which are InnoDB ,MyISAM , NDB ,Memory etc. These storage engines are used as pluggable storage enginer where tables created by user are plugged with them. Features of MySQL: MySQL language is easy to use as compared to other programming language like C,C++, Java etc. By learning with some basic command we can work , create and interact with Database. MySQL consist of Data Security layer which protect the data from violator. Also, passwords are encrypted in MySQL. MySQL follow Client-Server Architecture where Client request Commands and instructions and Server will produce output as soon as the instruction is matched. MySQL is free to use under Community version of it. So we can download it from MySQL website and work on it freely. MySQL use multithreading which makes it Scalable. It can handle any amount of data .The default file size limit is 4 GB, but we can increase it according to our need. MySQL is considered as one of the fast database. It’s fastness is determined on the basis of large number of benchmark tests. MySQL is very flexible because it supports large number of embedded systems. MySQL is compatible to run on various operating system such as Windows, MacOS , Linux etc. MySQL allow transactions to be rolled back, commit and cash recovery. It has low memory leakage problem which increase its memory efficiency. MySQL version 8.0 provide dual password support , one is a current password and another is secondary password. With the help of this we can create new password. MySQL provide feature of Partitioning which improve performance of large databases. Attention reader! Don’t stop learning now. Get hold of all the important CS Theory concepts for SDE interviews with the CS Theory Course at a student-friendly price and become industry ready. Reference architecture-of-MySQL","categories":[],"tags":[{"name":"MySQL architecture","slug":"MySQL-architecture","permalink":"http://youuwd.github.io/tags/MySQL-architecture/"}]},{"title":"docker_net","slug":"docker-net","date":"2021-01-12T02:20:46.000Z","updated":"2021-08-12T02:30:08.649Z","comments":true,"path":"2021/01/12/docker-net/","link":"","permalink":"http://youuwd.github.io/2021/01/12/docker-net/","excerpt":"","text":"Docker 网络问题汇总Docker’s networking subsystem is pluggable, using drivers. Several drivers exist by default, and provide core networking functionality: bridge: The default network driver. If you don’t specify a driver, this is the type of network you are creating. Bridge networks are usually used when your applications run in standalone containers that need to communicate. See bridge networks. host: For standalone containers, remove network isolation between the container and the Docker host, and use the host’s networking directly. See use the host network. overlay: Overlay networks connect multiple Docker daemons together and enable swarm services to communicate with each other. You can also use overlay networks to facilitate communication between a swarm service and a standalone container, or between two standalone containers on different Docker daemons. This strategy removes the need to do OS-level routing between these containers. See overlay networks. macvlan: Macvlan networks allow you to assign a MAC address to a container, making it appear as a physical device on your network. The Docker daemon routes traffic to containers by their MAC addresses. Using the macvlan driver is sometimes the best choice when dealing with legacy applications that expect to be directly connected to the physical network, rather than routed through the Docker host’s network stack. See Macvlan networks. none: For this container, disable all networking. Usually used in conjunction with a custom network driver. none is not available for swarm services. See disable container networking. Network plugins: You can install and use third-party network plugins with Docker. These plugins are available from Docker Hub or from third-party vendors. See the vendor’s documentation for installing and using a given network plugin. 常用类型 bridge 很容易打通各个容器之间的通信 host 复用宿主机网络 1234#创建my-net私网（各容器通过my-net这个路由器通信，容器不能直接打通宿主机）docker network create my-net#删除my-net私网docker network rm my-net","categories":[],"tags":[{"name":"docker net","slug":"docker-net","permalink":"http://youuwd.github.io/tags/docker-net/"}]},{"title":"jdb","slug":"jdb","date":"2020-08-26T10:55:44.000Z","updated":"2021-08-12T02:30:08.649Z","comments":true,"path":"2020/08/26/jdb/","link":"","permalink":"http://youuwd.github.io/2020/08/26/jdb/","excerpt":"","text":"jdb官方 操作实例12345678910111213141516import java.util.concurrent.TimeUnit;public class Hello &#123; public static void main(String[] args) throws InterruptedException &#123; int wait = 20; if (args.length &gt; 0) &#123; wait = Integer.parseInt(args[0]); &#125; int i = 0; while (i++ &lt; wait) &#123; System.out.println(i); TimeUnit.SECONDS.sleep(10); &#125; System.out.println(&quot;exit...&quot;); &#125;&#125; 编译1234// com.sun.tools.example.debug.expr.ParseException: Name unknown: wait// wait = nulljavac -g Hello.java #没有-g参数，jdb print 变量 如上错误 执行12# win 系统指令有差异java -Xdebug -Xrunjdwp:transport=dt_socket,address=8888,server=y,suspend=y Hello IDEA Remote Debug","categories":[],"tags":[{"name":"debug jdb","slug":"debug-jdb","permalink":"http://youuwd.github.io/tags/debug-jdb/"}]},{"title":"ClassLoader","slug":"ClassLoader","date":"2020-07-06T02:49:03.000Z","updated":"2021-08-12T09:40:43.475Z","comments":true,"path":"2020/07/06/ClassLoader/","link":"","permalink":"http://youuwd.github.io/2020/07/06/ClassLoader/","excerpt":"","text":"不同的 ClassLoader 之间也会有合作，它们之间的合作是通过 parent 属性和双亲委派机制来完成的。parent 具有更高的加载优先级。除此之外，parent 还表达了一种共享关系，当多个子 ClassLoader 共享同一个 parent 时，那么这个 parent 里面包含的类可以认为是所有子 ClassLoader 共享的。这也是为什么 BootstrapClassLoader 被所有的类加载器视为祖先加载器，JVM 核心类库自然应该被共享。 双亲委派 双亲委派规则可能会变成三亲委派，四亲委派，取决于你使用的父加载器是谁，它会一直递归委派到根加载器。 自定义加载器1234567891011121314151617181920212223242526272829303132333435363738class ClassLoader &#123; // 加载入口，定义了双亲委派规则 Class loadClass(String name) &#123; // 是否已经加载了 Class t = this.findFromLoaded(name); if(t == null) &#123; // 交给双亲 t = this.parent.loadClass(name) &#125; if(t == null) &#123; // 双亲都不行，只能靠自己了 t = this.findClass(name); &#125; return t; &#125; // 交给子类自己去实现 Class findClass(String name) &#123; throw ClassNotFoundException(); &#125; // 组装Class对象 Class defineClass(byte[] code, String name) &#123; return buildClassFromCode(code, name); &#125;&#125;class CustomClassLoader extends ClassLoader &#123; Class findClass(String name) &#123; // 寻找字节码 byte[] code = findCodeFromSomewhere(name); // 组装Class对象 return this.defineClass(code, name); &#125;&#125; 自定义类加载器不易破坏双亲委派规则，不要轻易覆盖 loadClass 方法。否则可能会导致自定义加载器无法加载内置的核心类库。在使用自定义加载器时，要明确好它的父加载器是谁，将父加载器通过子类的构造器传入。如果父类加载器是 null，那就表示父加载器是「根加载器」。 Class.forName vs ClassLoader.loadClass 这两个方法都可以用来加载目标类，它们之间有一个小小的区别，那就是 Class.forName() 方法可以获取原生类型的 Class，而 ClassLoader.loadClass() 则会报错。 123456789101112Class&lt;?&gt; x = Class.forName(&quot;[I&quot;);System.out.println(x);x = ClassLoader.getSystemClassLoader().loadClass(&quot;[I&quot;);System.out.println(x);---------------------class [IException in thread &quot;main&quot; java.lang.ClassNotFoundException: [I... 钻石依赖项目管理上有一个著名的概念叫着「钻石依赖」，是指软件依赖导致同一个软件包的两个版本需要共存而不能冲突。 我们平时使用的 maven 是这样解决钻石依赖的，它会从多个冲突的版本中选择一个来使用，如果不同的版本之间兼容性很糟糕，那么程序将无法正常编译运行。Maven 这种形式叫「扁平化」依赖管理。 使用 ClassLoader 可以解决钻石依赖问题。不同版本的软件包使用不同的 ClassLoader 来加载，位于不同 ClassLoader 中名称一样的类实际上是不同的类。下面让我们使用 URLClassLoader 来尝试一个简单的例子，它默认的父加载器是 AppClassLoader。 12345678910111213141516171819202122232425262728293031323334$ cat ~/source/jcl/v1/Dep.javapublic class Dep &#123; public void print() &#123; System.out.println(&quot;v1&quot;); &#125;&#125;$ cat ~/source/jcl/v2/Dep.javapublic class Dep &#123; public void print() &#123; System.out.println(&quot;v1&quot;); &#125;&#125;$ cat ~/source/jcl/Test.javapublic class Test &#123; public static void main(String[] args) throws Exception &#123; String v1dir = &quot;file:///Users/qianwp/source/jcl/v1/&quot;; String v2dir = &quot;file:///Users/qianwp/source/jcl/v2/&quot;; URLClassLoader v1 = new URLClassLoader(new URL[]&#123;new URL(v1dir)&#125;); URLClassLoader v2 = new URLClassLoader(new URL[]&#123;new URL(v2dir)&#125;); Class&lt;?&gt; depv1Class = v1.loadClass(&quot;Dep&quot;); Object depv1 = depv1Class.getConstructor().newInstance(); depv1Class.getMethod(&quot;print&quot;).invoke(depv1); Class&lt;?&gt; depv2Class = v2.loadClass(&quot;Dep&quot;); Object depv2 = depv2Class.getConstructor().newInstance(); depv2Class.getMethod(&quot;print&quot;).invoke(depv2); System.out.println(depv1Class.equals(depv2Class)); &#125;&#125; 12345678910$ cd ~/source/jcl/v1$ javac Dep.java$ cd ~/source/jcl/v2$ javac Dep.java$ cd ~/source/jcl$ javac Test.java$ java Testv1v2false 在这个例子中如果两个 URLClassLoader 指向的路径是一样的，下面这个表达式还是 false，因为即使是同样的字节码用不同的 ClassLoader 加载出来的类都不能算同一个类 我们还可以让两个不同版本的 Dep 类实现同一个接口，这样可以避免使用反射的方式来调用 Dep 类里面的方法。 123Class&lt;?&gt; depv1Class = v1.loadClass(&quot;Dep&quot;);IPrint depv1 = (IPrint)depv1Class.getConstructor().newInstance();depv1.print() ClassLoader 固然可以解决依赖冲突问题，不过它也限制了不同软件包的操作界面必须使用反射或接口的方式进行动态调用。Maven 没有这种限制，它依赖于虚拟机的默认懒惰加载策略，运行过程中如果没有显示使用定制的 ClassLoader，那么从头到尾都是在使用 AppClassLoader，而不同版本的同名类必须使用不同的 ClassLoader 加载，所以 Maven 不能完美解决钻石依赖。 如果你想知道有没有开源的包管理工具可以解决钻石依赖的，我推荐你了解一下 sofa-ark，它是蚂蚁金服开源的轻量级类隔离框架。 Thread.contextClassLoader12345678910111213class Thread &#123; ... private ClassLoader contextClassLoader; public ClassLoader getContextClassLoader() &#123; return contextClassLoader; &#125; public void setContextClassLoader(ClassLoader cl) &#123; this.contextClassLoader = cl; &#125; ...&#125; contextClassLoader「线程上下文类加载器」，这究竟是什么东西？ 首先 contextClassLoader 是那种需要显示使用的类加载器，如果你没有显示使用它，也就永远不会在任何地方用到它。你可以使用下面这种方式来显示使用它 1Thread.currentThread().getContextClassLoader().loadClass(name); 这意味着如果你使用 forName(string name) 方法加载目标类，它不会自动使用 contextClassLoader。那些因为代码上的依赖关系而懒惰加载的类也不会自动使用 contextClassLoader来加载。 其次线程的 contextClassLoader 默认是从父线程那里继承过来的，所谓父线程就是创建了当前线程的线程。程序启动时的 main 线程的 contextClassLoader 就是 AppClassLoader。这意味着如果没有人工去设置，那么所有的线程的 contextClassLoader 都是 AppClassLoader。 那这个 contextClassLoader 究竟是做什么用的？我们要使用前面提到了类加载器分工与合作的原理来解释它的用途。 它可以做到跨线程共享类，只要它们共享同一个 contextClassLoader。父子线程之间会自动传递 contextClassLoader，所以共享起来将是自动化的。 如果不同的线程使用不同的 contextClassLoader，那么不同的线程使用的类就可以隔离开来。 如果我们对业务进行划分，不同的业务使用不同的线程池，线程池内部共享同一个 contextClassLoader，线程池之间使用不同的 contextClassLoader，就可以很好的起到隔离保护的作用，避免类版本冲突。 如果我们不去定制 contextClassLoader，那么所有的线程将会默认使用 AppClassLoader，所有的类都将会是共享的。","categories":[],"tags":[{"name":"jvm classloader","slug":"jvm-classloader","permalink":"http://youuwd.github.io/tags/jvm-classloader/"}]},{"title":"mysql-xa","slug":"mysql-xa","date":"2020-06-15T09:31:42.000Z","updated":"2021-08-12T02:30:08.650Z","comments":true,"path":"2020/06/15/mysql-xa/","link":"","permalink":"http://youuwd.github.io/2020/06/15/mysql-xa/","excerpt":"","text":"MySQL XA 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455boolean logXaCommands = true; // 获得资源管理器操作接口实例 RM1 Connection conn1 = DriverManager.getConnection(&quot;jdbc:mysql://localhost:33060/d1&quot;, &quot;root&quot;, &quot;pass&quot;); XAConnection xaConn1 = new MysqlXAConnection((JdbcConnection)conn1, logXaCommands); XAResource rm1 = xaConn1.getXAResource(); // 获得资源管理器操作接口实例 RM2 Connection conn2 = DriverManager.getConnection(&quot;jdbc:mysql://localhost:33060/d2&quot;, &quot;root&quot;, &quot;pass&quot;); XAConnection xaConn2 = new MysqlXAConnection((JdbcConnection)conn2, logXaCommands); XAResource rm2 = xaConn2.getXAResource(); // AP请求TM执行一个分布式事务，TM生成全局事务id byte[] gtrid = &quot;g12345&quot;.getBytes(); int formatId = 1; try &#123; // ==============分别执行RM1和RM2上的事务分支==================== // TM生成rm1上的事务分支id byte[] bqual1 = &quot;b00001&quot;.getBytes(); Xid xid1 = new MysqlXid(gtrid, bqual1, formatId); // 执行rm1上的事务分支 One of TMNOFLAGS, TMJOIN, or TMRESUME. rm1.start(xid1, XAResource.TMNOFLAGS); // 业务1：插入user表 PreparedStatement ps1 = conn1.prepareStatement(&quot;insert into t1 values (10,&#x27;ab&#x27;)&quot;); ps1.execute(); rm1.end(xid1, XAResource.TMSUCCESS); // TM生成rm2上的事务分支id byte[] bqual2 = &quot;b00002&quot;.getBytes(); Xid xid2 = new MysqlXid(gtrid, bqual2, formatId); // 执行rm2上的事务分支 rm2.start(xid2, XAResource.TMNOFLAGS); // 业务2：插入user_msg表 PreparedStatement ps2 = conn2.prepareStatement(&quot;insert into t2 values (20,&#x27;cd&#x27;)&quot;); ps2.execute(); rm2.end(xid2, XAResource.TMSUCCESS); // ===================两阶段提交================================ // phase1：询问所有的RM 准备提交事务分支 int rm1Prepare = rm1.prepare(xid1); int rm2Prepare = rm2.prepare(xid2); // phase2：提交所有事务分支 boolean onePhase = false; //TM判断有2个事务分支，所以不能优化为一阶段提交 if (rm1Prepare == XAResource.XA_OK &amp;&amp; rm2Prepare == XAResource.XA_OK) &#123; //所有事务分支都prepare成功，提交所有事务分支 rm1.commit(xid1, onePhase); rm2.commit(xid2, onePhase); &#125; else &#123; //如果有事务分支没有成功，则回滚 rm1.rollback(xid1); rm1.rollback(xid2); &#125; &#125; catch (XAException e) &#123; // 如果出现异常，也要进行回滚 e.printStackTrace(); &#125; 事务落在同一个MySQL12345678910111213141516171819202122+---------------+------+----------------+-----------+-------------+----------------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+---------------+------+----------------+-----------+-------------+----------------------------------------------+| binlog.000001 | 4 | Format_desc | 1 | 125 | Server ver: 8.0.20, Binlog ver: 4 || binlog.000001 | 125 | Previous_gtids | 1 | 156 | || binlog.000001 | 156 | Anonymous_Gtid | 1 | 235 | SET @@SESSION.GTID_NEXT= &#x27;ANONYMOUS&#x27; || binlog.000001 | 235 | Query | 1 | 345 | XA START X&#x27;673132333435&#x27;,X&#x27;623030303031&#x27;,1 || binlog.000001 | 345 | Table_map | 1 | 399 | table_id: 94 (d1.t1) || binlog.000001 | 399 | Write_rows | 1 | 442 | table_id: 94 flags: STMT_END_F || binlog.000001 | 442 | Query | 1 | 550 | XA END X&#x27;673132333435&#x27;,X&#x27;623030303031&#x27;,1 || binlog.000001 | 550 | XA_prepare | 1 | 598 | XA PREPARE X&#x27;673132333435&#x27;,X&#x27;623030303031&#x27;,1 || binlog.000001 | 598 | Anonymous_Gtid | 1 | 677 | SET @@SESSION.GTID_NEXT= &#x27;ANONYMOUS&#x27; || binlog.000001 | 677 | Query | 1 | 787 | XA START X&#x27;673132333435&#x27;,X&#x27;623030303032&#x27;,1 || binlog.000001 | 787 | Table_map | 1 | 841 | table_id: 96 (d2.t2) || binlog.000001 | 841 | Write_rows | 1 | 884 | table_id: 96 flags: STMT_END_F || binlog.000001 | 884 | Query | 1 | 992 | XA END X&#x27;673132333435&#x27;,X&#x27;623030303032&#x27;,1 || binlog.000001 | 992 | XA_prepare | 1 | 1040 | XA PREPARE X&#x27;673132333435&#x27;,X&#x27;623030303032&#x27;,1 || binlog.000001 | 1040 | Anonymous_Gtid | 1 | 1117 | SET @@SESSION.GTID_NEXT= &#x27;ANONYMOUS&#x27; || binlog.000001 | 1117 | Query | 1 | 1228 | XA COMMIT X&#x27;673132333435&#x27;,X&#x27;623030303031&#x27;,1 || binlog.000001 | 1228 | Anonymous_Gtid | 1 | 1305 | SET @@SESSION.GTID_NEXT= &#x27;ANONYMOUS&#x27; || binlog.000001 | 1305 | Query | 1 | 1416 | XA COMMIT X&#x27;673132333435&#x27;,X&#x27;623030303032&#x27;,1 |+---------------+------+----------------+-----------+-------------+----------------------------------------------+ 事务落在2个不同MySQLMySQL 11234567891011121314+---------------+-----+----------------+-----------+-------------+----------------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+---------------+-----+----------------+-----------+-------------+----------------------------------------------+| binlog.000001 | 4 | Format_desc | 1 | 125 | Server ver: 8.0.20, Binlog ver: 4 || binlog.000001 | 125 | Previous_gtids | 1 | 156 | || binlog.000001 | 156 | Anonymous_Gtid | 1 | 235 | SET @@SESSION.GTID_NEXT= &#x27;ANONYMOUS&#x27; || binlog.000001 | 235 | Query | 1 | 345 | XA START X&#x27;673132333435&#x27;,X&#x27;623030303031&#x27;,1 || binlog.000001 | 345 | Table_map | 1 | 399 | table_id: 101 (d1.t1) || binlog.000001 | 399 | Write_rows | 1 | 442 | table_id: 101 flags: STMT_END_F || binlog.000001 | 442 | Query | 1 | 550 | XA END X&#x27;673132333435&#x27;,X&#x27;623030303031&#x27;,1 || binlog.000001 | 550 | XA_prepare | 1 | 598 | XA PREPARE X&#x27;673132333435&#x27;,X&#x27;623030303031&#x27;,1 || binlog.000001 | 598 | Anonymous_Gtid | 1 | 675 | SET @@SESSION.GTID_NEXT= &#x27;ANONYMOUS&#x27; || binlog.000001 | 675 | Query | 1 | 786 | XA COMMIT X&#x27;673132333435&#x27;,X&#x27;623030303031&#x27;,1 |+---------------+-----+----------------+-----------+-------------+----------------------------------------------+ MySQL 21234567891011121314+---------------+-----+----------------+-----------+-------------+----------------------------------------------+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+---------------+-----+----------------+-----------+-------------+----------------------------------------------+| binlog.000001 | 4 | Format_desc | 1 | 125 | Server ver: 8.0.20, Binlog ver: 4 || binlog.000001 | 125 | Previous_gtids | 1 | 156 | || binlog.000001 | 156 | Anonymous_Gtid | 1 | 235 | SET @@SESSION.GTID_NEXT= &#x27;ANONYMOUS&#x27; || binlog.000001 | 235 | Query | 1 | 345 | XA START X&#x27;673132333435&#x27;,X&#x27;623030303032&#x27;,1 || binlog.000001 | 345 | Table_map | 1 | 399 | table_id: 106 (d2.t2) || binlog.000001 | 399 | Write_rows | 1 | 442 | table_id: 106 flags: STMT_END_F || binlog.000001 | 442 | Query | 1 | 550 | XA END X&#x27;673132333435&#x27;,X&#x27;623030303032&#x27;,1 || binlog.000001 | 550 | XA_prepare | 1 | 598 | XA PREPARE X&#x27;673132333435&#x27;,X&#x27;623030303032&#x27;,1 || binlog.000001 | 598 | Anonymous_Gtid | 1 | 675 | SET @@SESSION.GTID_NEXT= &#x27;ANONYMOUS&#x27; || binlog.000001 | 675 | Query | 1 | 786 | XA COMMIT X&#x27;673132333435&#x27;,X&#x27;623030303032&#x27;,1 |+---------------+-----+----------------+-----------+-------------+----------------------------------------------+","categories":[],"tags":[{"name":"mysql binlog xa","slug":"mysql-binlog-xa","permalink":"http://youuwd.github.io/tags/mysql-binlog-xa/"}]},{"title":"binlog-protocol","slug":"binlog-protocol","date":"2020-06-02T06:58:21.000Z","updated":"2021-08-12T02:30:08.648Z","comments":true,"path":"2020/06/02/binlog-protocol/","link":"","permalink":"http://youuwd.github.io/2020/06/02/binlog-protocol/","excerpt":"","text":"生成新的binlog1flush logs; 清空binlog1reset master; 格式Binlog files start with a Binlog File Header followed by a series of Binlog Event Header + Event + Event + Event Header A binlog file starts with a Binlog File Header [ fe &#39;bin&#39; ] EventEventHeader + Event Binlog Event headerThe binlog event header starts each event and is either 13 or 19 bytes long, depending on the binlog version. 12345674 timestamp1 event type4 server-id4 event-size if binlog-version &gt; 1:4 log pos2 flags 1234+---------+---------+---------+------------+-------------+-------+|timestamp|type code|server_id|event_length|next_position|flags ||4 bytes |1 byte |4 bytes |4 bytes |4 bytes |2 bytes|+---------+---------+---------+------------+-------------+-------+ Fields timestamp (4) – seconds since unix epoch event_type (1) – see Binlog Event Type server_id (4) – server-id of the originating mysql-server. Used to filter out events in circular replication. event_size (4) – size of the event (header, post-header, body) log_pos (4) – position of the next event flags (2) – see Binlog Event Flag Table 14.5 Binlog Versions Binlog version MySQL Version 1 MySQL 3.23 - &lt; 4.0.0 2 MySQL 4.0.0 - 4.0.1 3 MySQL 4.0.2 - &lt; 5.0.0 4 MySQL 5.0.0+ 目前市面上都是V4了，故EventHeader的长度可以默认为19 Binlog::FORMAT_DESCRIPTION_EVENT: FORMAT_DESCRIPTION_EVENT 是binlog文件的第一个 Event 123456789101112131415161718192021222324252627282930313233343536373839404142434445//https://sourcegraph.com/github.com/mysql/mysql-server/-/blob/libbinlogevents/src/binlog_event.cpp#L84:1/** The method returns the checksum algorithm used to checksum the binary log. For MySQL server versions &lt; 5.6, the algorithm is undefined. For the higher versions, the type is decoded from the FORMAT_DESCRIPTION_EVENT. @param buf buffer holding serialized FD event @param len netto (possible checksum is stripped off) length of the event buf @return the version-safe checksum alg descriptor where zero designates no checksum, 255 - the orginator is checksum-unaware (effectively no checksum) and the actuall [1-254] range alg descriptor.*/enum_binlog_checksum_alg Log_event_footer::get_checksum_alg(const char *buf, unsigned long len) &#123; BAPI_ENTER(&quot;Log_event_footer::get_checksum_alg(const char*, unsigned long)&quot;); enum_binlog_checksum_alg ret = BINLOG_CHECKSUM_ALG_UNDEF; char version[ST_SERVER_VER_LEN]; unsigned char version_split[3]; BAPI_ASSERT(buf[EVENT_TYPE_OFFSET] == FORMAT_DESCRIPTION_EVENT); if (len &gt; LOG_EVENT_MINIMAL_HEADER_LEN + ST_COMMON_HEADER_LEN_OFFSET + 1) &#123; uint8_t common_header_len = buf[LOG_EVENT_MINIMAL_HEADER_LEN + ST_COMMON_HEADER_LEN_OFFSET]; if (len &gt;= static_cast&lt;unsigned long&gt;(common_header_len + ST_SERVER_VER_OFFSET + ST_SERVER_VER_LEN)) &#123; memcpy(version, buf + common_header_len + ST_SERVER_VER_OFFSET, ST_SERVER_VER_LEN); version[ST_SERVER_VER_LEN - 1] = 0; do_server_version_split(version, version_split); if (version_product(version_split) &lt; checksum_version_product) ret = BINLOG_CHECKSUM_ALG_UNDEF; else &#123; size_t checksum_alg_offset = len - (BINLOG_CHECKSUM_ALG_DESC_LEN + BINLOG_CHECKSUM_LEN); ret = static_cast&lt;enum_binlog_checksum_alg&gt;(*(buf + checksum_alg_offset)); &#125; &#125; &#125; BAPI_RETURN(ret);&#125; A format description event is the first event of a binlog for binlog-version 4. It describes how the other events are layed out. Row Based Replication Events In Row Based replication the changed rows are sent to the slave which removes side-effects and makes it more reliable. Now all statements can be sent with RBR though. Most of the time you will see RBR and SBR side by side. TABLE_MAP_EVENT DELETE_ROWS_EVENTv0 UPDATE_ROWS_EVENTv0 WRITE_ROWS_EVENTv0 DELETE_ROWS_EVENTv1 UPDATE_ROWS_EVENTv1 WRITE_ROWS_EVENTv1 DELETE_ROWS_EVENTv2 UPDATE_ROWS_EVENTv2 WRITE_ROWS_EVENTv2 12345678900000004 87 77 d4 5e|0f|01 00 00 00|79 00 00 00|7d 00 00 |.w.^.....y...&#125;..|00000014 00|00 00|04 00|38 2e 30 2e 32 30 00 00 00 00 00 |.....8.0.20.....|00000024 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................|00000034 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................|00000044 00 00 00 00 00 00 00|87 77 d4 5e|13|00 0d 00 08 |........w.^.....|00000054 00 00 00 00 04 00 04 00 00 00|61|00 04 1a 08 00 |..........a.....|00000064 00 00 08 08 08 02 00 00 00 0a 0a 0a 2a 2a 00 12 |............**..|00000074 34 00 0a 28|01|63 c8 ff 8b |4..(.c....w.^#..| Event Header timestamp: 87 77 d4 5e #1590982535 event type: 0f # FORMAT_DESCRIPTION_EVENT server-id: 01 00 00 00 #1 event-size: 79 00 00 00 #121 log pos: 7d 00 00 00 #125 position of the next event flag: 00 00 #0 Event Body (FORMAT_DESCRIPTION_EVENT) binlog-version: 04 00 #4 mysql-server version: 38 2e 30 2e 32 30 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 #8.0.20 create timestamp: 87 77 d4 5e #1590982535 event header length: 13 #19 固定值 event type header lengths： 00 0d 00 08 00 00 00 00 04 00 04 00 00 00 # 长度(15-1) data length: 61 #97 ==&gt; #check sum block = event-size - event header length - data length = 121-19-97 = 5 skip: 121(eventSize)-19(header)-2(binlogVersion)-50(serverVersion)-4(time)-1(headerLength)-14(typeHeaderLength)-1(dataLength)-5(checkSumBlock) = 25 check sum type: 01 #1 CRC32 例如：TABLE_MAP_EVENT 12345678910111213141516171819post-header: if post_header_len == 6 &#123; 4 table id &#125; else &#123; 6 table id &#125; 2 flagspayload: 1 schema name length string schema name 1 [00] 1 table name length string table name 1 [00] lenenc-int column-count string.var_len [length=$column-count] column-def lenenc-str column-meta-def n NULL-bitmask, length: (column-count + 8) / 7 12345+=====================================+| | fixed part (post-header) || data +----------------------------+| | variable part (payload) |+=====================================+ 参考","categories":[],"tags":[{"name":"binlog protocol","slug":"binlog-protocol","permalink":"http://youuwd.github.io/tags/binlog-protocol/"}]},{"title":"mysql-server","slug":"mysql-server","date":"2020-06-02T02:16:25.000Z","updated":"2021-08-12T02:30:08.650Z","comments":true,"path":"2020/06/02/mysql-server/","link":"","permalink":"http://youuwd.github.io/2020/06/02/mysql-server/","excerpt":"","text":"源码1https://github.com/mysql/mysql-server.git 1git clone git@github.com:mysql/mysql-server.git 编译12345678cmake \\-DCMAKE_INSTALL_PREFIX=/tmp/mysql_data/mysql-8.0-rc \\-DMYSQL_DATADIR=/tmp/mysql_data/mysql-8.0-rc/data \\-DSYSCONFDIR=/tmp/mysql_data/mysql-8.0-rc \\-DMYSQL_UNIX_ADDR=/tmp/mysql_data/mysql-8.0-rc/data/mysql.sock \\-DWITH_DEBUG=1 \\-DDOWNLOAD_BOOST=1 \\-DWITH_BOOST=/tmp/boost_1_72","categories":[],"tags":[{"name":"mysql server","slug":"mysql-server","permalink":"http://youuwd.github.io/tags/mysql-server/"}]},{"title":"docker_mysql","slug":"docker-mysql","date":"2020-06-01T02:20:46.000Z","updated":"2021-08-12T02:30:08.649Z","comments":true,"path":"2020/06/01/docker-mysql/","link":"","permalink":"http://youuwd.github.io/2020/06/01/docker-mysql/","excerpt":"","text":"拉取镜像1docker pull mysql 启动指令123456789# 简单启动docker run --name mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tagdocker run --name mysql -v /tmp/mysql:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=pass -d mysql:tag# 端口及目录映射docker run --name mysql-3306 -v /tmp/mysql:/var/lib/mysql -p 33060:3306 -e MYSQL_ROOT_PASSWORD=pass -d mysql:tag 1234# 常用docker run --name mysql-3306 -v /tmp/mysql:/var/lib/mysql -p 33060:3306 -e MYSQL_ROOT_PASSWORD=pass -d mysql --default-authentication-plugin=mysql_native_passwordALTER USER &#x27;root&#x27;@&#x27;%&#x27; IDENTIFIED WITH mysql_native_password BY &#x27;pass&#x27;;","categories":[],"tags":[{"name":"docker mysql","slug":"docker-mysql","permalink":"http://youuwd.github.io/tags/docker-mysql/"}]},{"title":"big_endian","slug":"big-endian","date":"2020-04-26T03:00:36.000Z","updated":"2021-08-12T02:30:08.648Z","comments":true,"path":"2020/04/26/big-endian/","link":"","permalink":"http://youuwd.github.io/2020/04/26/big-endian/","excerpt":"","text":"Big Endian and Little EndianA load word or store word instruction uses only one memory address. The lowest address of the four bytes is used for the address of a block of four contiguous bytes. How is a 32-bit pattern held in the four bytes of memory? There are 32 bits in the four bytes and 32 bits in the pattern, but a choice has to be made about which byte of memory gets what part of the pattern. There are two ways that computers commonly do this: Big Endian Byte Order: The most significant byte (the “big end”) of the data is placed at the byte with the lowest address. The rest of the data is placed in order in the next three bytes in memory. Little Endian Byte Order: The least significant byte (the “little end”) of the data is placed at the byte with the lowest address. The rest of the data is placed in order in the next three bytes in memory. In these definitions, the data, a 32-bit pattern, is regarded as a 32-bit unsigned integer. The “most significant” byte is the one for the largest powers of two: 231, …, 224. The “least significant” byte is the one for the smallest powers of two: 27, …, 20. For example, say that the 32-bit pattern 0x12345678 is stored at address 0x00400000. The most significant byte is 0x12; the least significant is 0x78. Within a byte the order of the bits is the same for all computers (no matter how the bytes themselves are arranged). 一、字节序字节序，也就是字节的顺序，指的是多字节的数据在内存中的存放顺序。 在几乎所有的机器上，多字节对象都被存储为连续的字节序列。例如：如果C/C++中的一个int型变量 a 的起始地址是&amp;a = 0x100，那么 a 的四个字节将被存储在存储器的0x100, 0x101, 0x102, 0x103位置。 根据整数 a 在连续的 4 byte 内存中的存储顺序，字节序被分为大端序（Big Endian） 与 小端序（Little Endian）两类。 然后就牵涉出两大CPU派系： Motorola 6800，PowerPC 970，SPARC（除V9外）等处理器采用 Big Endian方式存储数据； x86系列，VAX，PDP-11等处理器采用Little Endian方式存储数据。 另外，还有一些处理器像ARM, DEC Alpha的字节序是可配置的。 二、大端与小端那么，到底什么是大端，什么是小端？ 如下图： 我相信上面的图已经够直观了。也就是说： Big Endian 是指低地址端 存放 高位字节。 Little Endian 是指低地址端 存放 低位字节。 各自的优势： Big Endian：符号位的判定固定为第一个字节，容易判断正负。 Little Endian：长度为1，2，4字节的数，排列方式都是一样的，数据类型转换非常方便。 三、为什么要注意字节序如果你写的程序只在单机环境下面运行，并且不和别人的程序打交道，那么你完全可以忽略字节序的存在。 但是，如果你的程序要跟别人的程序产生交互呢？ 比如，当一个 C/C++ 的程序要与一个 Java 程序交互时： C/C++语言编写的程序里数据存储顺序是跟编译平台所在的CPU相关的，而现在比较普遍的 x86 处理器是 Little Endian JAVA编写的程序则唯一采用 Big Endian 方式来存储数据 试想，如果你的C/C++程序将变量 a = 0x12345678 的首地址传递给了Java程序，由于Java采取 Big Endian 方式存储数据，很自然的它会将你的数据翻译为 0x78563412。显然，问题就出现了！！！ 另外，网络传输一般采用 Big Endian，也被称之为网络字节序，或网络序。当两台采用不同字节序的主机通信时，在发送数据之前都必须经过字节序的转换成为网络字节序后再进行传输。 四、判断机器的字节序由于 C/C++ 存储数据时的字节序依赖所在平台的CPU，所以我们可以通过C/C++程序判定机器的端序： 12345678void Endianness()&#123; int a = 0x12345678; if( *((char*)&amp;a) == 0x12) cout &lt;&lt; &quot;Big Endian&quot; &lt;&lt; endl; else cout &lt;&lt; &quot;Little Endian&quot; &lt;&lt; endl;&#125; 五、网络序和主机序网络字节序：TCP/IP各层协议将字节序定义为 Big Endian，因此TCP/IP协议中使用的字节序是大端序。 主机字节序：整数在内存中存储的顺序，现在 Little Endian 比较普遍。（不同的 CPU 有不同的字节序） 在进行网络通信时 通常需要调用相应的函数进行主机序和网络序的转换。Berkeley socket API 定义了一组转换函数，用于16和32bit整数在网络序和本机字节序之间的转换。htonl，htons用于本机序转换到网络序；ntohl，ntohs用于网络序转换到本机序。","categories":[],"tags":[{"name":"Endian 字节序 网络通信","slug":"Endian-字节序-网络通信","permalink":"http://youuwd.github.io/tags/Endian-%E5%AD%97%E8%8A%82%E5%BA%8F-%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1/"}]},{"title":"iptables","slug":"iptables","date":"2020-04-24T06:28:14.000Z","updated":"2021-08-12T02:30:08.649Z","comments":true,"path":"2020/04/24/iptables/","link":"","permalink":"http://youuwd.github.io/2020/04/24/iptables/","excerpt":"","text":"## netstat123456789101112131415161718192021222324-a或--all：显示所有连线中的Socket；-A&lt;网络类型&gt;或--&lt;网络类型&gt;：列出该网络类型连线中的相关地址；-c或--continuous：持续列出网络状态；-C或--cache：显示路由器配置的快取信息；-e或--extend：显示网络其他相关信息；-F或--fib：显示FIB；-g或--groups：显示多重广播功能群组组员名单；-h或--help：在线帮助；-i或--interfaces：显示网络界面信息表单；-l或--listening：显示监控中的服务器的Socket；-M或--masquerade：显示伪装的网络连线；-n或--numeric：直接使用ip地址，而不通过域名服务器；-N或--netlink或--symbolic：显示网络硬件外围设备的符号连接名称；-o或--timers：显示计时器；-p或--programs：显示正在使用Socket的程序识别码和程序名称；-r或--route：显示Routing Table；-s或--statistice：显示网络工作信息统计表；-t或--tcp：显示TCP传输协议的连线状况；-u或--udp：显示UDP传输协议的连线状况；-v或--verbose：显示指令执行过程；-V或--version：显示版本信息；-w或--raw：显示RAW传输协议的连线状况；-x或--unix：此参数的效果和指定&quot;-A unix&quot;参数相同；--ip或--inet：此参数的效果和指定&quot;-A inet&quot;参数相同。 12345678910111213141516171819netstat -a #列出所有端口netstat -at #列出所有tcp端口netstat -au #列出所有udp端口netstat -l #只显示监听端口netstat -lt #只列出所有监听 tcp 端口netstat -lu #只列出所有监听 udp 端口netstat -lx #只列出所有监听 UNIX 端口netstat -s #显示所有端口的统计信息netstat -st #显示TCP端口的统计信息netstat -su #显示UDP端口的统计信息netstat -pt #在netstat输出中显示 PID 和进程名称netstat -ntu | grep :80 | awk &#x27;&#123;print $5&#125;&#x27; | cut -d: -f1 | awk &#x27;&#123;++ip[$1]&#125; END &#123;for(i in ip) print ip[i],&quot;\\t&quot;,i&#125;&#x27; | sort -nr #查看连接某服务端口最多的的IP地址netstat -nt | grep -e 127.0.0.1 -e 0.0.0.0 -e ::: -v | awk &#x27;/^tcp/ &#123;++state[$NF]&#125; END &#123;for(i in state) print i,&quot;\\t&quot;,state[i]&#125;&#x27; #TCP各种状态列表 iptables12345678910111213141516-t&lt;表&gt;：指定要操纵的表；-A：向规则链中添加条目；-D：从规则链中删除条目；-i：向规则链中插入条目；-R：替换规则链中的条目；-L：显示规则链中已有的条目；-F：清楚规则链中已有的条目；-Z：清空规则链中的数据包计算器和字节计数器；-N：创建新的用户自定义规则链；-P：定义规则链中的默认目标；-h：显示帮助信息；-p：指定要匹配的数据包协议类型；-s：指定要匹配的数据包源ip地址；-j&lt;目标&gt;：指定要跳转的目标；-i&lt;网络接口&gt;：指定数据包进入本机的网络接口；-o&lt;网络接口&gt;：指定数据包要离开本机所使用的网络接口。 1iptables -t 表名 &lt;-A/I/D/R&gt; 规则链名 [规则号] &lt;-i/o 网卡名&gt; -p 协议名 &lt;-s 源IP/源子网&gt; --sport 源端口 &lt;-d 目标IP/目标子网&gt; --dport 目标端口 -j 动作 清除已有规则12345iptables -Fiptables -Xiptables -Ziptables -L -n --line-number #显示编号iptables -D INPUT 2 #删除INPUT链编号为2的规则 123456789iptables -A INPUT -s 127.0.0.1 -d 127.0.0.1 -j ACCEPT #允许本地回环接口(即运行本机访问本机)iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT #允许已建立的或相关连的通行iptables -A OUTPUT -j ACCEPT #允许所有本机向外的访问iptables -A INPUT -p tcp --dport 22 -j ACCEPT #允许访问22端口iptables -A INPUT -p tcp --dport 80 -j ACCEPT #允许访问80端口iptables -A INPUT -p tcp --dport 21 -j ACCEPT #允许ftp服务的21端口iptables -A INPUT -p tcp --dport 20 -j ACCEPT #允许FTP服务的20端口iptables -A INPUT -j REJECT #禁止其他未允许的规则访问iptables -A FORWARD -j REJECT #禁止其他未允许的规则访问 样例12sudo iptables -I FORWARD -p tcp --dport 8080 -j DROP # 不响应对8080的请求，等待超时（效果：Operation timed out）sudo iptables -I INPUT -p tcp --dport 8080 -j REJECT # 直接拒绝其他机器连接本机8080 （效果：Connection refused）","categories":[],"tags":[{"name":"Linux Iptables Netstat 端口","slug":"Linux-Iptables-Netstat-端口","permalink":"http://youuwd.github.io/tags/Linux-Iptables-Netstat-%E7%AB%AF%E5%8F%A3/"}]},{"title":"nginx-gray","slug":"nginx-gray","date":"2019-11-20T09:52:25.000Z","updated":"2021-08-12T02:30:08.650Z","comments":true,"path":"2019/11/20/nginx-gray/","link":"","permalink":"http://youuwd.github.io/2019/11/20/nginx-gray/","excerpt":"","text":"Nginx 灰度测试 灰度测试在系统重构过程中是必不可少的，很多公司有自己的灰度解决方案。对于初创型或者小型团队，缺少必要的工具，因此这里借用nginx的转发（反向代理）能力做一下灰度测试。 Nginx配置Nginx配置文件主要分4部分 main(全局设置)： main部分的指令将影响其他所有的设置 server(主机设置)： server部分的指令主要作用于指定的主机和端口 upstream(负载均衡服务器设置)： upstream指令主要作用于负载均衡的设置 location(指定网页的设置): 主要用于匹配上的网页的设置。首先匹配 =，其次匹配^~, 其次是按文件中顺序的正则匹配，最后是交给 / 通用匹配。当有匹配成功时候，停止匹配，按当前匹配规则处理请求。 proxy_pass 在nginx中配置proxy_pass代理转发时，如果在proxy_pass后面的url加/，表示绝对根路径；如果没有/，表示相对路径，把匹配的路径部分也给代理走。 假设下面四种情况分别用 http://192.168.1.1/proxy/test.html 进行访问。 CASE 1: 123location /proxy/ &#123; proxy_pass http://127.0.0.1/;&#125; 代理到URL：http://127.0.0.1/test.html CASE 2: 123location /proxy/ &#123; proxy_pass http://127.0.0.1;#少了一个/&#125; 代理到URL：http://127.0.0.1/proxy/test.html CASE 3: 123location /proxy/ &#123; proxy_pass http://127.0.0.1/v1/;#加了一个子路径&#125; 代理到URL：http://127.0.0.1/v1/test.html CASE 4: 123location /proxy/ &#123; proxy_pass http://127.0.0.1/v1;#加了一个前缀&#125; 代理到URL：http://127.0.0.1/v1test.html 灰度粒度URL级别123location /api_to_gray &#123; proxy_pass http://target_endpoint/api_to_gray;&#125; 参数级别12345678location /api_to_gray &#123; //$arg_param 是url里面的参数，$http_param 是header里面的参数 if ($arg_param = &quot;value&quot;)&#123; add_header Version &#x27;V2&#x27;; proxy_pass http://target_endpoint/api_to_gray; &#125; proxy_pass http://original_endpoint;&#125; 参考文档Nginx 内置变量","categories":[],"tags":[{"name":"nginx 灰度","slug":"nginx-灰度","permalink":"http://youuwd.github.io/tags/nginx-%E7%81%B0%E5%BA%A6/"}]},{"title":"Linux 文件对比命令","slug":"file-diff","date":"2019-11-06T05:34:37.000Z","updated":"2021-08-12T02:30:08.649Z","comments":true,"path":"2019/11/06/file-diff/","link":"","permalink":"http://youuwd.github.io/2019/11/06/file-diff/","excerpt":"","text":"comm 指令1comm [-123][--help][--version][第1个文件][第2个文件] 参数： -1 不显示只在第1个文件里出现过的列。 -2 不显示只在第2个文件里出现过的列。 -3 不显示只在第1和第2个文件里出现过的列。 –help 在线帮助。 –version 显示版本信息。 需要排序，即便排序也不一定正确，所以不建议使用，适合对比极少数同行差异的文件。 diff 指令同comm指令，也是逐行对比，如果同样的内容处于不同行中，对比结果也不是期望的 1diff [-abBcdefHilnNpPqrstTuvwy][-&lt;行数&gt;][-C &lt;行数&gt;][-D &lt;巨集名称&gt;][-I &lt;字符或字符串&gt;][-S &lt;文件&gt;][-W &lt;宽度&gt;][-x &lt;文件或目录&gt;][-X &lt;文件&gt;][--help][--left-column][--suppress-common-line][文件或目录1][文件或目录2] grep 指令1grep [-abcEFGhHilLnqrsvVwxy][-A&lt;显示列数&gt;][-B&lt;显示列数&gt;][-C&lt;显示列数&gt;][-d&lt;进行动作&gt;][-e&lt;范本样式&gt;][-f&lt;范本文件&gt;][--help][范本样式][文件或目录...] 123456# 查看file2比file1多出的内容grep -v -x -f file1 file2# 查看file1和file2中单独存在的内容（差集1+差集2）grep -v -x -f file1 file2 &amp;&amp; grep -v -x -f file2 file1 # 查看file1和file2的交集grep -x -f file1 file2 -x –line-regexp : 只显示全列符合的列。 -f &lt;规则文件&gt; 或 –file=&lt;规则文件&gt;: 指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。","categories":[],"tags":[{"name":"Linux diff comm grep","slug":"Linux-diff-comm-grep","permalink":"http://youuwd.github.io/tags/Linux-diff-comm-grep/"}]},{"title":"nginx-variables","slug":"nginx-variables","date":"2019-10-15T11:44:12.000Z","updated":"2021-08-12T02:30:08.650Z","comments":true,"path":"2019/10/15/nginx-variables/","link":"","permalink":"http://youuwd.github.io/2019/10/15/nginx-variables/","excerpt":"","text":"Nginx 内置变量大全源码 1234567891011121314151617181920212223242526272829303132333435363738394041$args //请求中的的参数名，即“?”后面的arg_name=arg_value形式的arg_name$arg_PARAMETER //这是参数的一个匹配模式,PARAMETER为具体的参数名,$arg_PARAMETER就表示获取具体的参数值,例如上面的$arg_name就是获取url中name的值$is_args //判断url是否带参数，如果带，则返回一个？,否则返回一个空字符串$http_user_agent //获取的是客户端访问代理的类型,请求头中的信息$sent_http_content_type //获取的是http响应头中content_type的值$sent_http_content_length //获取的是http响应头重的content_length的值$request_filename //该变量获取的是请求的文件在linux服务器上的完整的绝对路径$request_method //该表示获取的是http请求的方法$request_uri //该变量表示的原始请求的uri，包括参数。所谓原始请求就是即使在内部做了重定向之后也不会变化$uri //获取的是当前请求的uri，不包括参数$content_length //获取的是http请求头中Content-Length的值$content_type //获取的是http请求头中的Content-Type字段，不过这里也没显示。。。$document_root //获取的是请求url的文件所在的目录路径$document_uri //当前请求的uri，从上面的信息来看,和uri的效果是一样的$remote_addr //获取的是客户端的ip地址,这里为什么是10.0.10.11呢，因为我是在本机上用curl测试的，即使客户端也是服务器$remote_port //获取客户端的访问端口，这个端口是随机的$remote_user //获取客户端的认证用户信息，这里因为没有用认证，所谓显示为空$server_protocol //表示服务器端想客户端发送响应的协议$server_addr //服务器的地址$server_name //客户端访问服务端的域名，即url中的域名(通配符不自动解析)$server_port //服务器端做出响应的端口号$binary_remote_addr //显示二进制的客户端地址$host //和server_name一样，表示的是域名$hostname //表示服务器端的主机名$proxy_add_x_forwarded_for //获取的是客户端的真实ip地址$proxy_host //该变量获取的是upstream的上游代理名称，例如upstream backend $proxy_port //该变量表示的是要代理到的端口$proxy_protocol_addr //代理头部中客户端的ip地址，或者是一个空的字符串$upstream_addr //代理到上游的服务器地址信息$upstream_cache_status //proxy的缓存状态，例如这里第一次访问为MISS，第二次访问时为HIT$upstream_response_length //上游服务器响应报文的长度$upstream_response_time //上游服务器响应的时间$upstream_status //上游服务器响应的状态码$scheme //表示的是使用http的访问协议 http or https$limit_rate //表示当前连接的限速是多少，0表示无限制$query_string //表示的是查询字符串，也就是url中的参数，和$args一样$realpath_root //表示的是请求页面的真实所在目录的路径 和$document_root是一样的","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://youuwd.github.io/tags/nginx/"}]},{"title":"proxy-in-mybatis","slug":"proxy-in-mybatis","date":"2019-10-11T11:02:19.000Z","updated":"2021-08-12T02:30:08.650Z","comments":true,"path":"2019/10/11/proxy-in-mybatis/","link":"","permalink":"http://youuwd.github.io/2019/10/11/proxy-in-mybatis/","excerpt":"","text":"代理在Mybatis里面的使用 主要位于org.apache.ibatis.binding包里面 代理实现 org.apache.ibatis.session.defaults.DefaultSqlSession#getMapper 12345SqlSession.getMapper ---&gt; Configuration.getMapper ---&gt; MapperRegistry.getMapper ---&gt; mapperProxyFactory.newInstance ---&gt; Proxy.newProxyInstance command 来自 mapper的注解或者xml配置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// org.apache.ibatis.binding.MapperMethod#executepublic Object execute(SqlSession sqlSession, Object[] args) &#123; Object result; switch (command.getType()) &#123; case INSERT: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.insert(command.getName(), param)); break; &#125; case UPDATE: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.update(command.getName(), param)); break; &#125; case DELETE: &#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.delete(command.getName(), param)); break; &#125; case SELECT: if (method.returnsVoid() &amp;&amp; method.hasResultHandler()) &#123; executeWithResultHandler(sqlSession, args); result = null; &#125; else if (method.returnsMany()) &#123; result = executeForMany(sqlSession, args); &#125; else if (method.returnsMap()) &#123; result = executeForMap(sqlSession, args); &#125; else if (method.returnsCursor()) &#123; result = executeForCursor(sqlSession, args); &#125; else &#123; Object param = method.convertArgsToSqlCommandParam(args); result = sqlSession.selectOne(command.getName(), param); if (method.returnsOptional() &amp;&amp; (result == null || !method.getReturnType().equals(result.getClass()))) &#123; result = Optional.ofNullable(result); &#125; &#125; break; case FLUSH: result = sqlSession.flushStatements(); break; default: throw new BindingException(&quot;Unknown execution method for: &quot; + command.getName()); &#125; if (result == null &amp;&amp; method.getReturnType().isPrimitive() &amp;&amp; !method.returnsVoid()) &#123; throw new BindingException(&quot;Mapper method &#x27;&quot; + command.getName() + &quot; attempted to return null from a method with a primitive return type (&quot; + method.getReturnType() + &quot;).&quot;); &#125; return result; &#125;","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://youuwd.github.io/categories/Mybatis/"}],"tags":[{"name":"Mybatis Proxy","slug":"Mybatis-Proxy","permalink":"http://youuwd.github.io/tags/Mybatis-Proxy/"}]},{"title":"Mybatis源码解读","slug":"mybatis-unscramble","date":"2019-09-24T11:54:35.000Z","updated":"2021-08-12T02:30:08.650Z","comments":true,"path":"2019/09/24/mybatis-unscramble/","link":"","permalink":"http://youuwd.github.io/2019/09/24/mybatis-unscramble/","excerpt":"","text":"整体代码结构 几个核心包Executor Session SqlSession 数据库连接打开 org.apache.ibatis.transaction.jdbc.JdbcTransaction#openConnection Mapper 生成12345T org.apache.ibatis.session.defaults.DefaultSqlSession#getMapperT org.apache.ibatis.session.Configuration#getMapperT org.apache.ibatis.binding.MapperRegistry#getMapperT org.apache.ibatis.binding.MapperProxyFactory#newInstance(org.apache.ibatis.session.SqlSession)T java.lang.reflect.Proxy#newProxyInstance SQL流图 Select 流程123456789org.apache.ibatis.executor.CachingExecutor#query(ms,parameterObject,rowBounds,resultHandler)org.apache.ibatis.executor.BaseExecutor#query(ms,parameter,rowBounds,resultHandler,key,boundSql)org.apache.ibatis.executor.BaseExecutor#queryFromDatabaseorg.apache.ibatis.executor.SimpleExecutor#doQueryorg.apache.ibatis.executor.statement.RoutingStatementHandler#parameterizeorg.apache.ibatis.executor.statement.PreparedStatementHandler#parameterizeorg.apache.ibatis.scripting.defaults.DefaultParameterHandler#setParametersorg.apache.ibatis.executor.statement.RoutingStatementHandler#queryorg.apache.ibatis.executor.resultset.DefaultResultSetHandler#handleResultSets Executor ==&gt; Statement ==&gt; Parameter ==&gt; ResultSet 绿色 几个组件都是可以通过mybatis插件改写的，参考 mybatis plugin Executor (update, query, flushStatements, commit, rollback, getTransaction, close, isClosed) StatementHandler (prepare, parameterize, batch, update, query) ParameterHandler (getParameterObject, setParameters) ResultSetHandler (handleResultSets, handleOutputParameters)","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://youuwd.github.io/categories/Mybatis/"}],"tags":[{"name":"MyBatis","slug":"MyBatis","permalink":"http://youuwd.github.io/tags/MyBatis/"}]},{"title":"tcpdump及tshark 使用","slug":"tcpdump-tshark","date":"2019-09-23T11:19:37.000Z","updated":"2021-08-12T02:30:08.650Z","comments":true,"path":"2019/09/23/tcpdump-tshark/","link":"","permalink":"http://youuwd.github.io/2019/09/23/tcpdump-tshark/","excerpt":"","text":"通用抓包工具 tcpdump tshark (wireshark 命令行版) tshark 安装yum install -y wireshark http请求抓包 tcpdump方式： 1sudo tcpdump -A -s 0 &#x27;tcp port 8080 and (((ip[2:2] - ((ip[0]&amp;0xf)&lt;&lt;2)) - ((tcp[12]&amp;0xf0)&gt;&gt;2)) != 0)&#x27; tshark方式： 12# 加 -V 显示包体内容，否则仅url，response_code等sudo tshark -i eth0 -R &#x27;ip.addr ==100.100.17.97 and http&#x27; mysql 抓包 tcpdump方式 12345678910sudo tcpdump -i any -s 0 -l -w - dst port 3306 | strings | perl -e &#x27;while(&lt;&gt;) &#123; chomp; next if /^[^ ]+[ ]*$/; if(/^(SELECT|UPDATE|DELETE|INSERT|SET|COMMIT|ROLLBACK|CREATE|DROP|ALTER|CALL)/i) &#123; if (defined $q) &#123; print &quot;$q\\n&quot;; &#125; $q=$_; &#125; else &#123; $_ =~ s/^[ \\t]+//; $q.=&quot; $_&quot;; &#125;&#125;&#x27; tshark方式 12# time_delta 本次回包耗时（RTT）sudo tshark -i eth0 -R &quot;ip.addr==ip&quot; -d tcp.port==3306,mysql -o tcp.calculate_timestamps:true -T fields -e frame.number -e frame.time_epoch -e frame.time_delta_displayed -e ip.src -e tcp.srcport -e ip.dst -e tcp.dstport -e tcp.time_delta -e tcp.stream -e tcp.len -e mysql.query","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://youuwd.github.io/tags/Linux/"},{"name":"Net","slug":"Net","permalink":"http://youuwd.github.io/tags/Net/"},{"name":"Tcpdump","slug":"Tcpdump","permalink":"http://youuwd.github.io/tags/Tcpdump/"},{"name":"Tshark","slug":"Tshark","permalink":"http://youuwd.github.io/tags/Tshark/"}]},{"title":"tcpdump及tshark 使用","slug":"tcpdump","date":"2019-09-23T11:19:37.000Z","updated":"2021-08-12T02:30:08.650Z","comments":true,"path":"2019/09/23/tcpdump/","link":"","permalink":"http://youuwd.github.io/2019/09/23/tcpdump/","excerpt":"","text":"译自 A tcpdump Tutorial and Primer with Examples 有所增删，可以通过 man tcpdump 获取更详细信息 只要和网络沾边，都可以使用tcpdump来排查问题。 1 基础1.1 常用选项 -i any ：监听任意网络设备 -i eth0 ：监听eth0 -D ：列出所有可监听设备 -n ：不要把IP解析为主机名（显示IP） -nn ：不要把IP和PORT解析为主机名和服务（显示IP和端口） -q ：显示更少信息 -tttt ：更具有可读性的时间格式 -X ：以hex和ascii格式显示包内容 -XX ：同 -X , 同时包含以太网协议头 -v, -vv, -vvv ：显示更多信息 -c x ：最多抓取x个包，然后退出 -A ：以ASCII格式打印每个包（最小化link level的头）,适合抓web页面 -s ：Define the snaplength (size) of the capture in bytes. 使用 -s0 获取全部 -w file ：把结果输出到文件file -S ：Print absolute sequence numbers. 1.2 表达式表达式用于过滤抓到的包，有三类表达式 类型 host net port 数据流向 src dst 协议 tcp udp icmp 等 2 例子2.1 获取所有流量tcpdump -i any 当机器有多个网卡，不确定流量走哪个时，使用这个选项 2.2 获取eth0上的流量1tcpdump -i eth0 2.3 查看原始流量1tcpdump -nn -tttt -vv -S -c 10 2.4 查看指定host和port1tcpdump port 80 and host 10.129.204.105 2.5 以hex和ascii查看包内容1tcpdump -nn -v -X -s0 -c 1 tcp 2.6 指定数据的方向获取所有目标端口是80的流量 tcpdump -i any -nn -s0 -c 10 -A tcp and dst port 80 获取所有80端口的流量 tcpdump -i any -nn -s0 -c 10 -A tcp and port 80 2.7 获取指定协议的流量获取vrrp协议的流量，用于调试keepalive tcpdump vrrp 2.8 获取ipv6的流量1tcpdump ip6 2.9 获取某个端口范围的流量1tcpdump -nn portrange 21-23 and src host 10.136.110.179 2.10 基于包大小过滤12tcpdump -i any -nn port 80 and less 80tcpdump -i any -nn port 80 and greater 80 3 进阶3.1 表达式组合通过 and 或 &amp;&amp; or 或 || not 或 ！ 可以组合表达式 表达式的结合律有点奇怪，需要自己体会，例如： 监听80或8080并且来自10.129.204.105的请求 tcpdump -i any -nn -vv port 80 or 8080 and src host 10.129.204.105 tcpdump -i any -nn -vv port 80 or port 8080 and src host 10.129.204.105 监听80并且来自10.129.204.105的请求或监听8080的请求（没有来源IP限制） tcpdump -i any -nn -vv port 80 and src host 10.129.204.105 or port 8080 为了避免这些微妙的差别，可以使用 () ，注意这里的单引号 tcpdump -i any -nn -vv &#39;(port 80 or port 8080)&#39; and src host 10.129.204.105 3.2 指定源host和目标端口1tcpdump -i any -nn -vv port 80 and src host 10.129.204.105 3.3 目标是某台机器的所有非tcp请求1tcpdump -i any -nn dst host 10.136.110.179 and not tcp 3.4 来自某台机器的所有非22请求1tcpdump -i any -nn src host 10.129.204.105 and not dst port 22 3.5 获取tcp flag先了解下TCP和IP协议头，虽然最后有0~40个可选bytes，这里没用到，可以先忽略它们。TCP头20bytes，其中tcp flags在第13个byte（下标为0） |C|E|U|A|P|R|S|F| 。 12345678910111213141516171819202122232425262728293031323334TCP 0 15 31-----------------------------------------------------------------| source port | destination port |-----------------------------------------------------------------| sequence number |-----------------------------------------------------------------| acknowledgment number |-----------------------------------------------------------------| HL | rsvd |C|E|U|A|P|R|S|F| window size |-----------------------------------------------------------------| TCP checksum | urgent pointer |-----------------------------------------------------------------| optional data 0~40 bytes |----------------------------------------------------------------- |---------------| |C|E|U|A|P|R|S|F| |---------------| |7 5 3 0|IP 0| 1| 2| 3| 4| 5| 6| 7| 8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31-----------------------------------------------------------------------------------------------| version | IHL | DSCP | ECN | total length -----------------------------------------------------------------------------------------------| Identification | Flags | Fragment Offset -----------------------------------------------------------------------------------------------| TTL | Protocol | Header Checksum -----------------------------------------------------------------------------------------------| Source IP -----------------------------------------------------------------------------------------------| Destination IP ----------------------------------------------------------------------------------------------- 3.5.1 flag列表 URGENT (URG) tcp[13] &amp; 32 != 0 或 tcp[tcpflags] == tcp-urg ACKNOWLEDGE (ACK) tcp[13] &amp; 16 != 0 或 tcp[tcpflags] == tcp-ack PUSH (PSH) tcp[13] &amp; 8 != 0 或 tcp[tcpflags] == tcp-psh RESET (RST) tcp[13] &amp; 4 != 0 或 tcp[tcpflags] == tcp-rst SYNCHRONIZE (SYN) tcp[13] &amp; 2 != 0 或 tcp[tcpflags] == tcp-syn FINISH (FIN) tcp[13] &amp; 1 != 0 或 tcp[tcpflags] == tcp-fin 例如：获取所有SYN请求 tcpdump -i any -nn -A -s0 &#39;tcp[13] &amp; 2 != 0&#39; 3.5.2 获取tcp连接的开始和结束1tcpdump -i any -nn -s0 -X &#x27;tcp[tcpflags] &amp; (tcp-syn|tcp-fin) != 0&#x27; 3.5.3 获取所有HTTP GET请求tcp[12] 的高4位是TCP HEADER的长度（通常是20 bytes）,TCP之后是应用协议 0x47455420 是 GET 外加一个空格 tcpdump -i any -nn -s0 -X &#39;tcp[((tcp[12] &amp; 0xf0) &gt;&gt; 2):4] = 0x47455420&#39; 通常 tcpdump -i any -nn -s0 -X &#39;tcp[20:4] = 0x47455420&#39; 也是可以的 3.5.4 获取所有SSH连接10x5353482D` 是 `SSH-` `tcpdump -i any -nn -s0 -X &#x27;tcp[20:4] = 0x5353482D&#x27; 3.5.5 获取所有带数据的包1ip[2:2]` 整个IP包的长度 `(ip[0] &amp; 0xf) &lt;&lt;2` 是IP头的长度 `tcpdump -i any -nn -s0 -X port 80 and &#x27;(((ip[2:2] - ((ip[0]&amp;0xf)&lt;&lt;2)) - ((tcp[12]&amp;0xf0)&gt;&gt;2)) != 0)&#x27;","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://youuwd.github.io/tags/Linux/"},{"name":"Net","slug":"Net","permalink":"http://youuwd.github.io/tags/Net/"},{"name":"Tcpdump","slug":"Tcpdump","permalink":"http://youuwd.github.io/tags/Tcpdump/"}]},{"title":"Git Commit Rewrite","slug":"git-commit-rewrite","date":"2019-09-18T07:06:22.000Z","updated":"2021-08-12T02:30:08.649Z","comments":true,"path":"2019/09/18/git-commit-rewrite/","link":"","permalink":"http://youuwd.github.io/2019/09/18/git-commit-rewrite/","excerpt":"","text":"commit message 重写 commit 未 push git commit --amend commit 且 push 123456789101112#查看需要修改的commit idgit log# rebase到指定idgit rebase -i commit-id# 把需要修改的commit-id pick修改为edit，保存# 修改commit信息并保存git commit --amend# 继续直到回到当前分支git rebase --continue# 强制pushgit push -f rebase 使用风险极大，请确保当前分支是最新代码，且已经提交了所有本地修改，还要确保rebase期间没有其他人提交代码。","categories":[{"name":"Git","slug":"Git","permalink":"http://youuwd.github.io/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://youuwd.github.io/tags/Git/"}]},{"title":"Mybatis New Feture","slug":"mybatis-new-feture","date":"2019-09-16T11:47:27.000Z","updated":"2021-08-12T02:30:08.649Z","comments":true,"path":"2019/09/16/mybatis-new-feture/","link":"","permalink":"http://youuwd.github.io/2019/09/16/mybatis-new-feture/","excerpt":"","text":"Mybatis新特性之Stream AND MySQL Containercommit-id： 78fbabdb支持Mybatis对于fetchSize的支持 1@Options(fetchSize = Integer.MIN_VALUE) 之前版本报异常，连接被提前关闭 commit-id： 25ddbb9bMybatis支持MySQL容器的测试 123456&lt;dependency&gt; &lt;groupId&gt;org.testcontainers&lt;/groupId&gt; &lt;artifactId&gt;mysql&lt;/artifactId&gt; &lt;version&gt;1.12.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 这样，用户就不用担心没有可用的MySQL，来进行testcase编写了，有一个缺陷就是，容器测试，效率稍微有些低下。","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://youuwd.github.io/categories/Mybatis/"}],"tags":[{"name":"Mybatis MySQL","slug":"Mybatis-MySQL","permalink":"http://youuwd.github.io/tags/Mybatis-MySQL/"}]},{"title":"建站主题配置","slug":"create-site","date":"2019-09-11T07:49:56.000Z","updated":"2021-08-12T02:30:08.649Z","comments":true,"path":"2019/09/11/create-site/","link":"","permalink":"http://youuwd.github.io/2019/09/11/create-site/","excerpt":"","text":"选择主题这里选择了 hipaper 12345#in blog folder# 选择主题git clone https://github.com/iTimeTraveler/hexo-theme-hipaper.git themes/hipaper# 配置主题# 把Hexo主目录下 _config.yml 文件中的theme字段改为 hipaper 配置网站标题修改hexo配置文件&lt;blog_root&gt;/_config.yml 123title: #网站标题subsite：#网站副标题author: #作者名称 支持图片logo 12345678# Put your avatar.jpg into `hexo-site/themes/hipaper/source/` directory.# url is target link (E.g. `url: https://hexo.io/logo.svg` or `url: css/images/mylogo.jpg`)avatar: enable: true width: 124 height: 124 bottom: 10 url: https://hexo.io/logo.svg 配置tag及category12# 创建tags页面hexo new page tags 12345678# source/tags/index.md 修改为---#title: tagsdate: 2019-09-11 16:39:26type: tagslayout: tags---# caffolds/post.md scaffolds/draft.md 里面的tags: 修改为 tags: &#123;&#123; tags &#125;&#125; 12# 生产站点文档hexo g","categories":[{"name":"建站","slug":"建站","permalink":"http://youuwd.github.io/categories/%E5%BB%BA%E7%AB%99/"}],"tags":[{"name":"建站","slug":"建站","permalink":"http://youuwd.github.io/tags/%E5%BB%BA%E7%AB%99/"}]},{"title":"GitHub PR","slug":"github-pull-request","date":"2019-09-11T07:49:56.000Z","updated":"2021-08-12T02:30:08.649Z","comments":true,"path":"2019/09/11/github-pull-request/","link":"","permalink":"http://youuwd.github.io/2019/09/11/github-pull-request/","excerpt":"","text":"PR 流程1234567891011121314151617# fork 源代码到自己仓库git clone git@github.com:YouUWd/mybatis-3.git# 建立上游连接git remote add upstream git@github.com:mybatis/mybatis-3.git# 创建开发分支 (非必须)git checkout -b dev# 修改提交代码git statusgit add . git commit -m &quot;fix xxx&quot;git push origin dev# 同步代码git fetch upstreamgit rebase upstream/mastergit push origin master# GitHub 到自己仓库提交pr 我的第一个开源PRissue pull request","categories":[{"name":"Git","slug":"Git","permalink":"http://youuwd.github.io/categories/Git/"}],"tags":[{"name":"GitHub PR","slug":"GitHub-PR","permalink":"http://youuwd.github.io/tags/GitHub-PR/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-09-09T12:49:03.000Z","updated":"2021-08-12T02:30:08.649Z","comments":true,"path":"2019/09/09/hello-world/","link":"","permalink":"http://youuwd.github.io/2019/09/09/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"建站","slug":"建站","permalink":"http://youuwd.github.io/categories/%E5%BB%BA%E7%AB%99/"}],"tags":[]}],"categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://youuwd.github.io/categories/Mybatis/"},{"name":"Git","slug":"Git","permalink":"http://youuwd.github.io/categories/Git/"},{"name":"建站","slug":"建站","permalink":"http://youuwd.github.io/categories/%E5%BB%BA%E7%AB%99/"}],"tags":[{"name":"java maven docker mysql gitlab github","slug":"java-maven-docker-mysql-gitlab-github","permalink":"http://youuwd.github.io/tags/java-maven-docker-mysql-gitlab-github/"},{"name":"zsh oh-my-zsh","slug":"zsh-oh-my-zsh","permalink":"http://youuwd.github.io/tags/zsh-oh-my-zsh/"},{"name":"MySQL architecture","slug":"MySQL-architecture","permalink":"http://youuwd.github.io/tags/MySQL-architecture/"},{"name":"docker net","slug":"docker-net","permalink":"http://youuwd.github.io/tags/docker-net/"},{"name":"debug jdb","slug":"debug-jdb","permalink":"http://youuwd.github.io/tags/debug-jdb/"},{"name":"jvm classloader","slug":"jvm-classloader","permalink":"http://youuwd.github.io/tags/jvm-classloader/"},{"name":"mysql binlog xa","slug":"mysql-binlog-xa","permalink":"http://youuwd.github.io/tags/mysql-binlog-xa/"},{"name":"binlog protocol","slug":"binlog-protocol","permalink":"http://youuwd.github.io/tags/binlog-protocol/"},{"name":"mysql server","slug":"mysql-server","permalink":"http://youuwd.github.io/tags/mysql-server/"},{"name":"docker mysql","slug":"docker-mysql","permalink":"http://youuwd.github.io/tags/docker-mysql/"},{"name":"Endian 字节序 网络通信","slug":"Endian-字节序-网络通信","permalink":"http://youuwd.github.io/tags/Endian-%E5%AD%97%E8%8A%82%E5%BA%8F-%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1/"},{"name":"Linux Iptables Netstat 端口","slug":"Linux-Iptables-Netstat-端口","permalink":"http://youuwd.github.io/tags/Linux-Iptables-Netstat-%E7%AB%AF%E5%8F%A3/"},{"name":"nginx 灰度","slug":"nginx-灰度","permalink":"http://youuwd.github.io/tags/nginx-%E7%81%B0%E5%BA%A6/"},{"name":"Linux diff comm grep","slug":"Linux-diff-comm-grep","permalink":"http://youuwd.github.io/tags/Linux-diff-comm-grep/"},{"name":"nginx","slug":"nginx","permalink":"http://youuwd.github.io/tags/nginx/"},{"name":"Mybatis Proxy","slug":"Mybatis-Proxy","permalink":"http://youuwd.github.io/tags/Mybatis-Proxy/"},{"name":"MyBatis","slug":"MyBatis","permalink":"http://youuwd.github.io/tags/MyBatis/"},{"name":"Linux","slug":"Linux","permalink":"http://youuwd.github.io/tags/Linux/"},{"name":"Net","slug":"Net","permalink":"http://youuwd.github.io/tags/Net/"},{"name":"Tcpdump","slug":"Tcpdump","permalink":"http://youuwd.github.io/tags/Tcpdump/"},{"name":"Tshark","slug":"Tshark","permalink":"http://youuwd.github.io/tags/Tshark/"},{"name":"Git","slug":"Git","permalink":"http://youuwd.github.io/tags/Git/"},{"name":"Mybatis MySQL","slug":"Mybatis-MySQL","permalink":"http://youuwd.github.io/tags/Mybatis-MySQL/"},{"name":"建站","slug":"建站","permalink":"http://youuwd.github.io/tags/%E5%BB%BA%E7%AB%99/"},{"name":"GitHub PR","slug":"GitHub-PR","permalink":"http://youuwd.github.io/tags/GitHub-PR/"}]}